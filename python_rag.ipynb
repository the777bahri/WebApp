{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build an AI app!\n",
    "\n",
    "The following steps will cover:\n",
    "1. How to use GPT to create a chatbot in Python.\n",
    "2. How to add data to your own chatbot. \n",
    "3. Create a basic web app using GPT with your own data\n",
    "4. Create an improved web app that keeps track of the message history for improved context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get set up!\n",
    "\n",
    "To use GPT in this workshop we've set up a proxy that means you get easy access to Azure OpenAI services.\n",
    "\n",
    "To get access to the proxy service go to [this link](https://aka.ms/UTS-Tech-Fest-AI-Proxy) and sign in with your GitHub account.\n",
    "\n",
    "You will need the **key** and **endpoint** that you get from the proxy site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Make an AI chatbot in Python\n",
    "\n",
    "In this part you will get the key and end point and create the code to ask a question to Azure OpenAI service. \n",
    "\n",
    "### üåè Set up your environment\n",
    "1. Open the terminal using the top menu\n",
    "\n",
    "2. Set up a python virtual environment in the terminal with this command `python3 -m venv ai-app-env`\n",
    "\n",
    "3. Activate the virtual environment with this command `source ai-app-env/bin/activate`\n",
    "\n",
    "4. Run the `Hello World` code in the next cell and set your kernal for Jupyter notebooks, selected *\"Select Another Kernal\"* at the top to **ai-app-env** and click \"Install\" on the pop up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Add AI\n",
    "1. Go the the requirements.txt file and add `openai`\n",
    "\n",
    "2. In the terminal run the command `pip install -r requirements.txt`\n",
    "\n",
    "3. In the code snippet **below** import the OpenAIClient library at the top of the next code snippet like this: `from openai import AzureOpenAI`. \n",
    "\n",
    "4. In the code cell below fill in the key and endpoint in the variables `AOAI_ENDPOINT` and `AOAI_KEY` *(AOAI is short for Azure OpenAI)*\n",
    "\n",
    "5. In the section where the client is set up, set the following parameters:\n",
    "    - Set api_key to the AOAI_KEY constant you created\n",
    "    - Set azure_endpoint to the AOAI_ENDPOINT constant you created\n",
    "\n",
    "5. Run you code and see the output below the code cell. \n",
    "\n",
    "### üó£Ô∏è Change the tone of the AI and the question\n",
    "6. You can make the tone of the chat different but setting the SYSTEM_MESSAGE. Try make it talk like Elmo, a surf bro, or anything you like.\n",
    "\n",
    "7. Update the question variable to ask a different question.\n",
    "\n",
    "### üîÑ *Bonus: Ask more questions!* \n",
    "8. Create a `while True:` loop after the SYSTEM_MESSAGE variable is set. \n",
    "\n",
    "9. Use the `input` function to ask the user to input a question. Assign it to the question variable (instead of hard coding the question like it currently is).\n",
    "\n",
    "10. Make sure all the question and AI related content is *inside* the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Using cached openai-1.35.3-py3-none-any.whl (327 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Using cached pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/vscode/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting tqdm>4\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting idna>=2.8\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/vscode/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (1.2.1)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.18.4\n",
      "  Using cached pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, tqdm, sniffio, pydantic-core, numpy, idna, h11, distro, certifi, annotated-types, pydantic, pandas, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.4.0 certifi-2024.6.2 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 numpy-2.0.0 openai-1.35.3 pandas-2.2.2 pydantic-2.7.4 pydantic-core-2.18.4 pytz-2024.1 sniffio-1.3.1 tqdm-4.66.4 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just as the peach tree is not bothered by the rain, so too is age but a number that does not define us. Vladimir Putin, like the peach tree, has seen many seasons. He was born on the 7th of October in the year 1952. Thus, his age can be calculated based on the current year. As of 2021, he would be 69 years old. Yet, it is not the years in one's life, but the life in one's years that truly counts. \n",
      "\n",
      "(Source: https://www.biography.com/political-figure/vladimir-putin)\n",
      "Ah, like the evergreen bamboo, age is but a number to some. Vladimir Putin, the leader of Russia, was born on October 7, 1952. The journey of the sun and moon have circled many times since his birth, making him 69 years old as of 2021. Always remember, \"Yesterday is history, tomorrow is a mystery, but today is a gift. That is why it is called the present.\" (Source: Wikipedia)\n"
     ]
    }
   ],
   "source": [
    "# Imports go here\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# Put the keys and endpoints here (never put your real keys in the code)\n",
    "AOAI_ENDPOINT = \"https://polite-ground-030dc3103.4.azurestaticapps.net/api/v1\"\n",
    "AOAI_KEY = \"885479bb-a213-4645-94ec-9f113f61dc2a\"\n",
    "MODEL_NAME = \"gpt-4\"\n",
    "\n",
    "# Set up the client for AI Chat using the contstants and API Version\n",
    "client = AzureOpenAI(\n",
    "    api_key= AOAI_KEY,\n",
    "    azure_endpoint= AOAI_ENDPOINT,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# Set the tone of the conversation\n",
    "# SYSTEM_MESSAGE = \"You are a helpful AI assistant that can answer questions and provide information. You can also provide sources for your information.\"\n",
    "SYSTEM_MESSAGE = \"You are an are a helpful assistant who answers questions like Grand Master Oogway from kong fu panda. You can also provide sources for your information.\"\n",
    "while True:\n",
    "    # What question do you want to ask?\n",
    "    question = input(\"ask any question, or stop to stop\")\n",
    "    if question == \"stop\":\n",
    "        break\n",
    "    else:\n",
    "        # Create the message history\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "\n",
    "        # Get the answer using the GPT model (create 1 answer (n) and use a temperature of 0.7 to set it to be pretty creative/random)\n",
    "        response = client.chat.completions.create(model=MODEL_NAME,temperature=0.7,n=1,messages=messages)\n",
    "        answer = response.choices[0].message.content\n",
    "        print(answer)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to your chatbot\n",
    "Our chatbot now knows how to read and to write and has some general purpose knowledge. But it doens't know about many specific resources or new resources (from after the model was trainied). We'll be adding some data that we can search through before it answers the question.\n",
    "\n",
    "### üåè‚ôªÔ∏è Upate your environment\n",
    "1. Copy your previous code into the Python cell below. \n",
    "\n",
    "2. Go to the requirements.txt file and add `azure-search-documents` and `azure-core`\n",
    "\n",
    "3. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "\n",
    "4. At the top of your code import the libraries need to **search documents** and create **login credentials for Azure** like this\n",
    "    ```\n",
    "    from azure.search.documents import SearchClient\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    ```\n",
    "\n",
    "### üîé Add Search capabilties \n",
    "1. Add another constant called `SEARCH_ENDPOINT` and set it to the same things as your `AOAI_ENDPOINT` *(this is only the same because we are using the proxy service)*.\n",
    "\n",
    "2. Add another constant called `SEARCH_KEY` and set it to the same things as your `AOAI_KEY`.\n",
    "\n",
    "3. Add another constant called `AZURE_SEARCH_INDEX` and set it to `margiestravel` to link to the pre-made Azure blob container *(I have uploaded relevant documents to the Azure Blob storage prior to the session so it will work with the proxy server)*:\n",
    "\n",
    "4. Copy this code and put it under where the AI Chat Client is set up:\n",
    "\n",
    "    ```\n",
    "    search_client = SearchClient(\n",
    "        endpoint=<PUT THE SEARCH ENDPOINT CONTSTANT HERE>,\n",
    "        credential=AzureKeyCredential(<ADD SEARCH KEY CONSTANT HERE>),\n",
    "        index_name=<PUT YOUR CHOSEN SEARCH INDEX HERE>,\n",
    "        )\n",
    "    ```\n",
    "5. Put in the variable names for the Search Endpoint, Search Key, and Search Index.\n",
    "\n",
    "### üîéüß† Use your AI Search Client\n",
    "4. After you have asked the user for a question, put this bit of code to query the AI Search resource. \n",
    "     `search_results = search_client.search(search_text=question)`\n",
    "\n",
    "5. On the next line add this code to join all of the results together into on big text chunk:\n",
    "    `search_summary = \" \".join(result[\"content\"] for result in search_results)`\n",
    "\n",
    "6. Update the messages variable so the user message looks like this (to include the search results):\n",
    "    `{\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_results}`\n",
    "    \n",
    "7. Run your code and ask a question that relates to travel.\n",
    "\n",
    "### üìö *Bonus: Add more context with a message history* \n",
    "If you want to improve the quality of the results you can include the history of questions that have been asked. \n",
    "Work out how to build up the message list to include all the questions asked by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.35.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: azure-search-documents in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (11.4.0)\n",
      "Requirement already satisfied: azure-core in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.30.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement random (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for random\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, my friend, you inquire about Margie's Travel. It is a journey organizer, a guide to places far and wide. It opens doors to the world, offering passage to destinations like the bustling city of New York, the cultural hub of San Francisco, the shimmering oasis of Dubai, the vibrant haven of Las Vegas, and the historic charm of London. \n",
      "\n",
      "Margie's Travel provides the key to your journey, arranging flights, securing accommodations, organizing transfers, and even assisting with visas and currency exchange. It is the bridge between you and your dream destination. \n",
      "\n",
      "At the helm of this vessel are Marjorie Long, Logan Reid, Emma Luffman, and Deepak Nadar, true experts of travel. For more about their offerings and to embark on your own journey, you may visit their website at www.margiestravel.com. \n",
      "\n",
      "Remember, my friend, \"Yesterday is history, tomorrow is a mystery, but today is a gift. That is why it is called the present.\" Choose to unwrap the gift of travel with Margie's Travel today.\n"
     ]
    }
   ],
   "source": [
    "# Imports go here\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Put the keys and endpoints here (never put your real keys in the code)\n",
    "AOAI_ENDPOINT = \"https://polite-ground-030dc3103.4.azurestaticapps.net/api/v1\"\n",
    "SEARCH_ENDPOINT = AOAI_ENDPOINT\n",
    "AOAI_KEY = \"885479bb-a213-4645-94ec-9f113f61dc2a\"\n",
    "SEARCH_KEY = AOAI_KEY\n",
    "MODEL_NAME = \"gpt-4\"\n",
    "AZURE_SEARCH_INDEX = \"margiestravel\"\n",
    "\n",
    "# Set up the client for AI Chat using the contstants and API Version\n",
    "client = AzureOpenAI(\n",
    "    api_key= AOAI_KEY,\n",
    "    azure_endpoint= AOAI_ENDPOINT,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint= SEARCH_ENDPOINT,\n",
    "    credential=AzureKeyCredential(SEARCH_KEY),\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    ")\n",
    "\n",
    "\n",
    "# Set the tone of the conversation\n",
    "# SYSTEM_MESSAGE = \"You are a helpful AI assistant that can answer questions and provide information. You can also provide sources for your information.\"\n",
    "SYSTEM_MESSAGE = \"You are an are a helpful assistant who answers questions like Grand Master Oogway from kong fu panda. You can also provide sources for your information.\"\n",
    "while True:\n",
    "    # What question do you want to ask?\n",
    "    question = input(\"ask any question, or stop to stop\")\n",
    "    if question == \"stop\":\n",
    "        break\n",
    "    else:\n",
    "        search_results = search_client.search(search_text=question)\n",
    "\n",
    "        search_summary = \" \".join(result[\"content\"] for result in search_results)\n",
    "\n",
    "        # Create the message history\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            # {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary}\n",
    "        ]\n",
    "\n",
    "        # Get the answer using the GPT model (create 1 answer (n) and use a temperature of 0.7 to set it to be pretty creative/random)\n",
    "        response = client.chat.completions.create(model=MODEL_NAME,temperature=0.7,n=1,messages=messages)\n",
    "        answer = response.choices[0].message.content\n",
    "        print(answer)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.a: Turn your Python script into an web app!\n",
    "\n",
    "## üåè‚ôªÔ∏è Update your environment\n",
    "1. Go to the requirements.txt file and add `Flask==3.0.3` and `requests` to the list\n",
    "\n",
    "2. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "\n",
    "## üï∏Ô∏è Create your web app\n",
    "3. Go to the app.py file\n",
    "\n",
    "4. Copy in the the code from the above cell into the parts marked for imports, constants, and inside of the get_response function. \n",
    "\n",
    "5. Copy the following 2 routes in under the index route. \n",
    "\n",
    "    ```\n",
    "    # This is the route that shows the form the user asks a question on\n",
    "    @app.get('/test-ai')\n",
    "    def test_ai():\n",
    "        # Very basic form that sends a question to the /contextless-message endpoint\n",
    "        return \"\"\"\n",
    "        <h1>Ask a question!</h1>\n",
    "        <form method=\"post\" action=\"/test-ai\">\n",
    "            <textarea name=\"question\" placeholder=\"Ask a question\"></textarea>\n",
    "            <button type=\"submit\">Ask</button>\n",
    "        </form>\n",
    "        \"\"\"\n",
    "\n",
    "    # This is the route that the form sends the question to and sends back the response\n",
    "    @app.route(\"/test-ai\", methods=[\"POST\"])\n",
    "    def ask_response():\n",
    "        # Get the question from the form\n",
    "        question = request.form.get(\"question\")\n",
    "\n",
    "        # Return the response from the AI\n",
    "        return get_response(question)\n",
    "    ```\n",
    "\n",
    "## üëÄ Checkout your web app\n",
    "6. Run your code, this will start the web server.\n",
    "\n",
    "7. Click on the link/button to view the web page and navigate to the test-ai page from the hoem page. \n",
    "\n",
    "8. See if your AI is working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.b - A prettier AI question answers\n",
    "1. Add the following routes (under the other 3) to serve up the provided ask.html file with CSS. *(This uses JavaScript to return the form data in preparation for Part 4.)*\n",
    "    ```\n",
    "    @app.get('/ask')\n",
    "    def ask():\n",
    "        return render_template(\"ask.html\")\n",
    "\n",
    "\n",
    "    @app.route('/contextless-message', methods=['GET', 'POST'])\n",
    "    def contextless_message():\n",
    "        question = request.json['message']\n",
    "        resp = get_response(question)\n",
    "        return {\"resp\": resp[0]}\n",
    "    ```\n",
    "2. Run your server again and go to the /ask route on the server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Improve your app with a message history\n",
    "In this part we've provided a HTML template, JavaScript and CSS that handle the front end to have an ongoing conversation. \n",
    "Each time we will unpack both the question and the previous chat history (the context) from the JSON we receive in the request. \n",
    "\n",
    "1. Add these two routes to your app.py file under your other routes.\n",
    "    ```\n",
    "    @app.get('/chat')\n",
    "    def chat():\n",
    "        return render_template('chat.html')\n",
    "\n",
    "    @app.route(\"/context-message\", methods=[\"GET\", \"POST\"])\n",
    "    def context_message():\n",
    "        question = request.json[\"message\"]\n",
    "        context = request.json[\"context\"]\n",
    "\n",
    "        resp, context = get_response(question, context)\n",
    "        return {\"resp\": resp, \"context\": context}\n",
    "    ```\n",
    "\n",
    "2. Update your get_response function where you create the message variable, get rid of your existing message variable and replace it with this if statement. *(This will test if there is already a message history to add to or if one should be created.)*\n",
    "    ```\n",
    "    # Create a new message history if there isn't one\n",
    "    if not message_history:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    # Otherwise, append the user's question to the message history\n",
    "    else:\n",
    "        messages = message_history + [\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.35.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: azure-search-documents in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (11.4.0)\n",
      "Requirement already satisfied: azure-core in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.30.2)\n",
      "Collecting Flask==3.0.3 (from -r requirements.txt (line 5))\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (2.7.4)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in ./.venv/lib/python3.10/site-packages (from azure-search-documents->-r requirements.txt (line 3)) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in ./.venv/lib/python3.10/site-packages (from azure-search-documents->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.10/site-packages (from azure-core->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->-r requirements.txt (line 6)) (2024.6.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.14.0)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->Flask==3.0.3->-r requirements.txt (line 5))\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.18.4)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, click, blinker, Werkzeug, Jinja2, Flask\n",
      "Successfully installed Flask-3.0.3 Jinja2-3.1.4 MarkupSafe-2.1.5 Werkzeug-3.0.3 blinker-1.8.2 click-8.1.7 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
