{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build an AI app!\n",
    "\n",
    "The following steps will cover:\n",
    "1. How to use GPT to create a chatbot in Python.\n",
    "2. How to add data to your own chatbot. \n",
    "3. Create a basic web app using GPT with your own data\n",
    "4. Create an improved web app that keeps track of the message history for improved context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get set up!\n",
    "\n",
    "To use GPT in this workshop we've set up a proxy that means you get easy access to Azure OpenAI services.\n",
    "\n",
    "To get access to the proxy service go to [this link](https://aka.ms/UTS-Tech-Fest-AI-Proxy) and sign in with your GitHub account.\n",
    "\n",
    "You will need the **key** and **endpoint** that you get from the proxy site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Make an AI chatbot in Python\n",
    "\n",
    "In this part you will get the key and end point and create the code to ask a question to Azure OpenAI service. \n",
    "\n",
    "### üåè Set up your environment\n",
    "1. Open the terminal using the top menu\n",
    "\n",
    "2. Set up a python virtual environment in the terminal with this command `python3 -m venv ai-app-env`\n",
    "\n",
    "3. Activate the virtual environment with this command `source ai-app-env/bin/activate`\n",
    "\n",
    "4. Run the `Hello World` code in the next cell and set your kernal for Jupyter notebooks, selected *\"Select Another Kernal\"* at the top to **ai-app-env** and click \"Install\" on the pop up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Add AI\n",
    "1. Go the the requirements.txt file and add `openai`\n",
    "\n",
    "2. In the terminal run the command `pip install -r requirements.txt`\n",
    "\n",
    "3. In the code snippet **below** import the OpenAIClient library at the top of the next code snippet like this: `from openai import AzureOpenAI`. \n",
    "\n",
    "4. In the code cell below fill in the key and endpoint in the variables `AOAI_ENDPOINT` and `AOAI_KEY` *(AOAI is short for Azure OpenAI)*\n",
    "\n",
    "5. In the section where the client is set up, set the following parameters:\n",
    "    - Set api_key to the AOAI_KEY constant you created\n",
    "    - Set azure_endpoint to the AOAI_ENDPOINT constant you created\n",
    "\n",
    "5. Run you code and see the output below the code cell. \n",
    "\n",
    "### üó£Ô∏è Change the tone of the AI and the question\n",
    "6. You can make the tone of the chat different but setting the SYSTEM_MESSAGE. Try make it talk like Elmo, a surf bro, or anything you like.\n",
    "\n",
    "7. Update the question variable to ask a different question.\n",
    "\n",
    "### üîÑ *Bonus: Ask more questions!* \n",
    "8. Create a `while True:` loop after the SYSTEM_MESSAGE variable is set. \n",
    "\n",
    "9. Use the `input` function to ask the user to input a question. Assign it to the question variable (instead of hard coding the question like it currently is).\n",
    "\n",
    "10. Make sure all the question and AI related content is *inside* the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports go here\n",
    "\n",
    "\n",
    "\n",
    "# Put the keys and endpoints here (never put your real keys in the code)\n",
    "AOAI_ENDPOINT = \n",
    "AOAI_KEY = \n",
    "MODEL_NAME = \"gpt-35-turbo-16k\"\n",
    "\n",
    "# Set up the client for AI Chat using the contstants and API Version\n",
    "client = AzureOpenAI(\n",
    "    api_key=,\n",
    "    azure_endpoint=,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# Set the tone of the conversation\n",
    "# SYSTEM_MESSAGE = \"You are a helpful AI assistant that can answer questions and provide information. You can also provide sources for your information.\"\n",
    "SYSTEM_MESSAGE = \"You are an are a helpful assistant who answers questions. You can also provide sources for your information.\"\n",
    "\n",
    "# What question do you want to ask?\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Create the message history\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "\n",
    "# Get the answer using the GPT model (create 1 answer (n) and use a temperature of 0.7 to set it to be pretty creative/random)\n",
    "response = client.chat.completions.create(model=MODEL_NAME,temperature=0.7,n=1,messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to your chatbot\n",
    "Our chatbot now knows how to read and to write and has some general purpose knowledge. But it doens't know about many specific resources or new resources (from after the model was trainied). We'll be adding some data that we can search through before it answers the question.\n",
    "\n",
    "### üåè‚ôªÔ∏è Upate your environment\n",
    "1. Copy your previous code into the Python cell below. \n",
    "\n",
    "2. Go to the requirements.txt file and add `azure-search-documents` and `azure-core`\n",
    "\n",
    "3. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "\n",
    "4. At the top of your code import the libraries need to **search documents** and create **login credentials for Azure** like this\n",
    "    ```\n",
    "    from azure.search.documents import SearchClient\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    ```\n",
    "\n",
    "### üîé Add Search capabilties \n",
    "1. Add another constant called `SEARCH_ENDPOINT` and set it to the same things as your `AOAI_ENDPOINT` *(this is only the same because we are using the proxy service)*.\n",
    "\n",
    "2. Add another constant called `SEARCH_KEY` and set it to the same things as your `AOAI_KEY`.\n",
    "\n",
    "3. Add another constant called `AZURE_SEARCH_INDEX` and set it to `margiestravel` to link to the pre-made Azure blob container *(I have uploaded relevant documents to the Azure Blob storage prior to the session so it will work with the proxy server)*:\n",
    "\n",
    "4. Copy this code and put it under where the AI Chat Client is set up:\n",
    "\n",
    "    ```\n",
    "    search_client = SearchClient(\n",
    "        endpoint=<PUT THE SEARCH ENDPOINT CONTSTANT HERE>,\n",
    "        credential=AzureKeyCredential(<ADD SEARCH KEY CONSTANT HERE>),\n",
    "        index_name=<PUT YOUR CHOSEN SEARCH INDEX HERE>,\n",
    "        )\n",
    "    ```\n",
    "5. Put in the variable names for the Search Endpoint, Search Key, and Search Index.\n",
    "\n",
    "### üîéüß† Use your AI Search Client\n",
    "4. After you have asked the user for a question, put this bit of code to query the AI Search resource. \n",
    "     `search_results = search_client.search(search_text=question)`\n",
    "\n",
    "5. On the next line add this code to join all of the results together into on big text chunk:\n",
    "    `search_summary = \" \".join(result[\"content\"] for result in search_results)`\n",
    "\n",
    "6. Update the messages variable so the user message looks like this (to include the search results):\n",
    "    `{\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_results}`\n",
    "    \n",
    "7. Run your code and ask a question that relates to travel.\n",
    "\n",
    "### üìö *Bonus: Add more context with a message history* \n",
    "If you want to improve the quality of the results you can include the history of questions that have been asked. \n",
    "Work out how to build up the message list to include all the questions asked by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################\n",
    "### Copy and paste your preious code here ###\n",
    "##############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.a: Turn your Python script into an web app!\n",
    "\n",
    "## üåè‚ôªÔ∏è Update your environment\n",
    "1. Go to the requirements.txt file and add `Flask==3.0.3` and `requests` to the list\n",
    "\n",
    "2. In the terminal run the command `pip install -r requirements.txt` again to install the new library in the list.\n",
    "\n",
    "## üï∏Ô∏è Create your web app\n",
    "3. Go to the app.py file\n",
    "\n",
    "4. Copy in the the code from the above cell into the parts marked for imports, constants, and inside of the get_response function. \n",
    "\n",
    "5. Copy the following 2 routes in under the index route. \n",
    "\n",
    "    ```\n",
    "    # This is the route that shows the form the user asks a question on\n",
    "    @app.get('/test-ai')\n",
    "    def test_ai():\n",
    "        # Very basic form that sends a question to the /contextless-message endpoint\n",
    "        return \"\"\"\n",
    "        <h1>Ask a question!</h1>\n",
    "        <form method=\"post\" action=\"/test-ai\">\n",
    "            <textarea name=\"question\" placeholder=\"Ask a question\"></textarea>\n",
    "            <button type=\"submit\">Ask</button>\n",
    "        </form>\n",
    "        \"\"\"\n",
    "\n",
    "    # This is the route that the form sends the question to and sends back the response\n",
    "    @app.route(\"/test-ai\", methods=[\"POST\"])\n",
    "    def ask_response():\n",
    "        # Get the question from the form\n",
    "        question = request.form.get(\"question\")\n",
    "\n",
    "        # Return the response from the AI\n",
    "        return get_response(question)\n",
    "    ```\n",
    "\n",
    "## üëÄ Checkout your web app\n",
    "6. Run your code, this will start the web server.\n",
    "\n",
    "7. Click on the link/button to view the web page and navigate to the test-ai page from the hoem page. \n",
    "\n",
    "8. See if your AI is working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.b - A prettier AI question answers\n",
    "1. Add the following routes (under the other 3) to serve up the provided ask.html file with CSS. *(This uses JavaScript to return the form data in preparation for Part 4.)*\n",
    "    ```\n",
    "    @app.get('/ask')\n",
    "    def ask():\n",
    "        return render_template(\"ask.html\")\n",
    "\n",
    "\n",
    "    @app.route('/contextless-message', methods=['GET', 'POST'])\n",
    "    def contextless_message():\n",
    "        question = request.json['message']\n",
    "        resp = get_response(question)\n",
    "        return {\"resp\": resp[0]}\n",
    "    ```\n",
    "2. Run your server again and go to the /ask route on the server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Improve your app with a message history\n",
    "In this part we've provided a HTML template, JavaScript and CSS that handle the front end to have an ongoing conversation. \n",
    "Each time we will unpack both the question and the previous chat history (the context) from the JSON we receive in the request. \n",
    "\n",
    "1. Add these two routes to your app.py file under your other routes.\n",
    "    ```\n",
    "    @app.get('/chat')\n",
    "    def chat():\n",
    "        return render_template('chat.html')\n",
    "\n",
    "    @app.route(\"/context-message\", methods=[\"GET\", \"POST\"])\n",
    "    def context_message():\n",
    "        question = request.json[\"message\"]\n",
    "        context = request.json[\"context\"]\n",
    "\n",
    "        resp, context = get_response(question, context)\n",
    "        return {\"resp\": resp, \"context\": context}\n",
    "    ```\n",
    "\n",
    "2. Update your get_response function where you create the message variable, get rid of your existing message variable and replace it with this if statement. *(This will test if there is already a message history to add to or if one should be created.)*\n",
    "    ```\n",
    "    # Create a new message history if there isn't one\n",
    "    if not message_history:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    # Otherwise, append the user's question to the message history\n",
    "    else:\n",
    "        messages = message_history + [\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nSources: \" + search_summary},\n",
    "        ]\n",
    "    ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
